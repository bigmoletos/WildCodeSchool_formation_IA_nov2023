{"cells":[{"cell_type":"markdown","metadata":{"id":"IcqKo0hRIPcM"},"source":["# ARIMA Model with Python\n","\n"," AutoRegressive Integrated Moving Average. It is a class of models that captures a suite of different standard temporal structures in time series data."]},{"cell_type":"markdown","metadata":{"id":"v0NlFtG7IWOB"},"source":["# Dataset\n","**Minimum Daily Temperatures Dataset**\n","\n","Use the following dataset that describes the minimum daily temperatures over 10 years (1981-1990) in the city of Melbourne, Australia. The source of the data is credited as the Australian Bureau of Meteorology.\n","The units are in degrees Celsius and there are 3,650 observations.\n","\n","Download the dataset here:  https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv"]},{"cell_type":"markdown","metadata":{"id":"dIYgDZpfIioq"},"source":["**Load the dataset and create a line plot of the time series**"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["import requests\n","import os\n","import pandas as pd\n","\n","def telecharger_et_charger_fichier(url, dossier_destination=None):\n","    \"\"\"\n","    Télécharge un fichier depuis une URL donnée, le sauvegarde dans un dossier spécifié,\n","    Si le dossier n'existe pas il est crée\n","    Par defaut enregistre le fichier dans un repertoire ../datas qui est à la racine du projet\n","    et charge le fichier dans un DataFrame en fonction de son format.\n","\n","    :param url: URL du fichier à télécharger.\n","    :param dossier_destination: Dossier de destination optionnel pour le fichier.\n","    :return: Tuple contenant le DataFrame original, sa copie, et le nom du fichier.\n","    \"\"\"\n","    # Initialiser df_original et df à None\n","    df_original, df = None, None\n","    try:\n","        # Déterminer le nom du fichier à partir de l'URL\n","        nom_fichier = url.split('/')[-1]\n","\n","        # Construire le chemin absolu du dossier de destination\n","        if dossier_destination is None:\n","            # Chemin par défaut relatif au script\n","            chemin_script = os.path.dirname(os.path.abspath(__file__))\n","            chemin_complet = os.path.join(chemin_script, \"..\", \"datas\", nom_fichier)\n","        else:\n","            # Utiliser le chemin de destination fourni\n","            chemin_complet = os.path.join(dossier_destination, nom_fichier)\n","\n","        # Créer le dossier de destination s'il n'existe pas\n","        os.makedirs(os.path.dirname(chemin_complet), exist_ok=True)\n","\n","        # Télécharger le fichier\n","        response = requests.get(url)\n","        response.raise_for_status()\n","\n","        # Écrire le contenu dans le fichier de destination\n","        with open(chemin_complet, 'wb') as file:\n","            file.write(response.content)\n","\n","        # Déterminer l'extension du fichier et charger dans un DataFrame\n","        extension = nom_fichier.split('.')[-1].lower()\n","        if extension in ['csv', 'txt']:\n","            df_original = pd.read_csv(chemin_complet, encoding='utf-8', header=0, index_col=0)\n","        elif extension == 'json':\n","            df_original = pd.read_json(chemin_complet, encoding='utf-8', orient='records')\n","        elif extension == 'xlsx':\n","            df_original = pd.read_excel(chemin_complet, index_col=0)\n","        else:\n","            print(f\"Format de fichier non pris en charge : {extension}\")\n","\n","        # Faire une copie du DataFrame si celui-ci a été chargé\n","        if df_original is not None:\n","            df = df_original.copy()\n","\n","        return df_original, df, chemin_complet\n","\n","    except requests.HTTPError as http_err:\n","        print(f\"Erreur HTTP lors du téléchargement du fichier : {http_err}\")\n","        return None, None, None\n","    except Exception as err:\n","        print(f\"Une erreur est survenue lors du téléchargement du fichier : {err}\")\n","        return None, None, None\n","\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# Chargement du df\n","url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv\"\n","# df_original, df, nom_fichier = telecharger_et_charger_csv(url)\n","df_original, df, nom_fichier = telecharger_et_charger_fichier( url, \"datas/csv\")\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["            Temp\n","Date            \n","1981-01-01  20.7\n","1981-01-02  17.9\n","1981-01-03  18.8\n","1981-01-04  14.6\n","1981-01-05  15.8\n","...          ...\n","1990-12-27  14.0\n","1990-12-28  13.6\n","1990-12-29  13.5\n","1990-12-30  15.7\n","1990-12-31  13.0\n","\n","[3650 rows x 1 columns]\n"]}],"source":["print(df)\n"]},{"cell_type":"markdown","metadata":{"id":"mJHK8lutI37m"},"source":["# Split the dataset\n","\n","Split the dataset into 2 subsets. The first part will be the training dataset that you will use to build an ARIMA model. The second part is the test dataset. It is these time steps that you will treat as out-of-sample.\n","\n","Write the code to load the dataset, split it into the training and validation datasets, and save them to files *dataset.csv* and *validation.csv* respectively.\n","\n","\n","**Instructions**\n","\n","The dataset contains data from January 1st 1981 to December 31st 1990.\n","Hold back the last 7 days of the dataset from December 1990 as the test dataset and treat those time steps as out of sample.\n","\n","Specifically 1990-12-25 to 1990-12-31"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSbTfEWNKnvd"},"outputs":[],"source":["# Your code here\n"]},{"cell_type":"markdown","metadata":{"id":"-DS_GJO_JxPj"},"source":["# Build the model\n","Check if the data is stationary. If it is not, make it stationary and develop a simple ARIMA model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"izYtHh-cIO8r"},"outputs":[],"source":["# Your code here\n"]},{"cell_type":"markdown","metadata":{"id":"kCN_NaYiMkwr"},"source":["# One-step out-of-sample forecast\n","A one-step forecast is a forecast of the very next time step in the sequence from the available data used to fit the model.\n","\n","In this case, we are interested in a one-step forecast of Christmas Day 1990: 1990-12-25\n","\n","**Instructions**\n","The statsmodel `ARIMAResults` object provides a `forecast()` function for making predictions.\n","\n","By default, this function makes a single step out-of-sample forecast. As such, you can call it directly and make your forecast. The result of the `forecast()` function is an array containing the forecast value, the standard error of the forecast, and the confidence interval information. You are only interested in the first element of this forecast.\n","\n","**Expected result: **\n","`Forecast: 14.861669`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WGZ9V9ZUNZam"},"outputs":[],"source":["# Your code here\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1G1Iknuhktm92UltDeZo2fFzM_mETmyDc","timestamp":1706689119689}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
