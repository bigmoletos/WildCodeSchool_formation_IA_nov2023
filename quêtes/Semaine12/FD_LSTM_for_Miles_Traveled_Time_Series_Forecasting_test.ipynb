{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations nécessaires\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.initializers import GlorotUniform\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_csv('Miles_Traveled.csv')\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df.set_index('DATE', inplace=True)\n",
    "df = df.resample('MS').mean()\n",
    "df = df.fillna(method='ffill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.initializers import GlorotUniform\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "458/458 [==============================] - 5s 5ms/step - loss: 0.0105\n",
      "Epoch 2/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0058\n",
      "Epoch 3/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0038\n",
      "Epoch 4/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0035\n",
      "Epoch 5/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0022\n",
      "Epoch 6/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0027\n",
      "Epoch 7/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0027\n",
      "Epoch 8/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0023\n",
      "Epoch 9/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0023\n",
      "Epoch 10/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0025\n",
      "Epoch 11/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0026\n",
      "Epoch 12/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0027\n",
      "Epoch 13/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0025\n",
      "Epoch 14/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0022\n",
      "Epoch 15/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0020\n",
      "Epoch 16/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0023\n",
      "Epoch 17/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0027\n",
      "Epoch 18/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0025\n",
      "Epoch 19/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0022\n",
      "Epoch 20/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0021\n",
      "Epoch 21/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0022\n",
      "Epoch 22/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0022\n",
      "Epoch 23/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0021\n",
      "Epoch 24/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0023\n",
      "Epoch 25/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0020\n",
      "Epoch 26/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0018\n",
      "Epoch 27/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0022\n",
      "Epoch 28/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0020\n",
      "Epoch 29/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0020\n",
      "Epoch 30/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0020\n",
      "106/106 [==============================] - 1s 1ms/step\n",
      "Mean Squared Error (MSE): 284870928.90005666\n",
      "Mean Absolute Percentage Error (MAPE): 0.05741670231100586\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configuration des données\n",
    "n_input = 12\n",
    "n_features = 1\n",
    "\n",
    "# Séparer les données en ensembles d'entraînement et de test\n",
    "train_size = int(len(df) * 0.8)\n",
    "train, test = df.iloc[:train_size], df.iloc[train_size:]\n",
    "\n",
    "# Mise à l'échelle des données\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "test_scaled = scaler.transform(test)\n",
    "\n",
    "# Création du générateur de séries temporelles\n",
    "train_generator = TimeseriesGenerator(\n",
    "    train_scaled, train_scaled, length=n_input, batch_size=1)\n",
    "\n",
    "# Création du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(150, activation='tanh', input_shape=(\n",
    "    n_input, n_features), kernel_initializer=GlorotUniform()))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "history = model.fit(train_generator, epochs=30)\n",
    "\n",
    "# Prédictions\n",
    "test_generator = TimeseriesGenerator(\n",
    "    test_scaled, test_scaled, length=n_input, batch_size=1)\n",
    "y_pred = model.predict(test_generator)\n",
    "\n",
    "# Inverser la mise à l'échelle pour obtenir les vraies valeurs\n",
    "y_pred_original = scaler.inverse_transform(y_pred)\n",
    "y_test_original = scaler.inverse_transform(test_scaled[n_input:])\n",
    "\n",
    "# Calcul des métriques\n",
    "mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "mape = mean_absolute_percentage_error(y_test_original, y_pred_original)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder l'architecture du modèle au format JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_LSTM.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Sauvegarder les poids du modèle au format HDF5\n",
    "model.save_weights(\"model_LSTM_weights.h5\")\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Charger l'architecture du modèle à partir du fichier JSON\n",
    "with open(\"model_LSTM.json\", \"r\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Charger les poids du modèle à partir du fichier HDF5\n",
    "loaded_model.load_weights(\"model_LSTM_weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 858ms/step\n"
     ]
    }
   ],
   "source": [
    "# Sélectionnez les derniers points de données de l'ensemble d'entraînement\n",
    "first_eval_batch = train_scaled[-n_input:]\n",
    "\n",
    "# Redimensionnez le lot pour correspondre au format attendu par le modèle\n",
    "# Le nouveau format doit être [1, n_input, n_features]\n",
    "first_eval_batch = first_eval_batch.reshape((1, n_input, n_features))\n",
    "\n",
    "# Maintenant, vous pouvez utiliser ce lot pour faire une première prédiction\n",
    "first_pred = model.predict(first_eval_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "First test prediction (original scale): [[228815.75]]\n"
     ]
    }
   ],
   "source": [
    "# Sélectionnez les derniers points de données de l'ensemble d'entraînement\n",
    "last_train_batch = train_scaled[-n_input:]\n",
    "\n",
    "# Redimensionnez le lot pour correspondre au format attendu par le modèle\n",
    "# Le format doit être [1, n_input, n_features]\n",
    "last_train_batch = last_train_batch.reshape((1, n_input, n_features))\n",
    "\n",
    "# Faire la prédiction pour le premier point de l'ensemble de test\n",
    "first_test_prediction = model.predict(last_train_batch)\n",
    "\n",
    "# Appliquer la transformation inverse pour obtenir la valeur originale\n",
    "first_test_prediction_original = scaler.inverse_transform(first_test_prediction)\n",
    "\n",
    "print(\"First test prediction (original scale):\", first_test_prediction_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 0: [0.78115076]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Prédiction 1: [0.8002224]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Prédiction 2: [0.8235569]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 3: [0.83758074]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Prédiction 4: [0.8414086]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Prédiction 5: [0.83165526]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 6: [0.81191933]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 7: [0.78909767]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 8: [0.7525571]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 9: [0.7217146]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 10: [0.6927597]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 11: [0.6878656]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 12: [0.7037435]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 13: [0.72451395]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prédiction 14: [0.746711]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 15: [0.76140165]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 16: [0.7642012]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 17: [0.7546254]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 18: [0.7347352]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 19: [0.70736223]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 20: [0.67601]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 21: [0.6474867]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Prédiction 22: [0.62889934]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prédiction 23: [0.62657857]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 24: [0.6391825]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 25: [0.6600335]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 26: [0.68067515]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 27: [0.69334257]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 28: [0.694282]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Prédiction 29: [0.68346316]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Prédiction 30: [0.6629636]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 31: [0.6358454]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 32: [0.6063884]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prédiction 33: [0.58069223]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 34: [0.56546324]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Prédiction 35: [0.56496793]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 36: [0.57803655]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 37: [0.598348]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 38: [0.6174058]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prédiction 39: [0.62827927]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 40: [0.6277448]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 41: [0.6159408]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Prédiction 42: [0.5949634]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 43: [0.56801295]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 44: [0.5395985]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 45: [0.5157318]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 46: [0.5025692]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 47: [0.503547]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 48: [0.5170606]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 49: [0.53679365]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prédiction 50: [0.5546522]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 51: [0.5642356]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Prédiction 52: [0.5626288]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 53: [0.5500632]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 54: [0.52868235]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prédiction 55: [0.50183326]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prédiction 56: [0.47419155]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Prédiction 57: [0.45168293]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 58: [0.43999875]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 59: [0.44197738]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prédiction 60: [0.45568323]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prédiction 61: [0.47488713]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Prédiction 62: [0.49185842]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 63: [0.5005578]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 64: [0.49826294]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 65: [0.4852628]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 66: [0.4637558]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prédiction 67: [0.43721366]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 68: [0.41040152]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Prédiction 69: [0.38909143]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 70: [0.378546]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Prédiction 71: [0.38115138]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Prédiction 72: [0.394799]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Prédiction 73: [0.4134429]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 74: [0.4297133]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 75: [0.437868]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 76: [0.43530977]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Prédiction 77: [0.42234236]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 78: [0.40119046]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Prédiction 79: [0.37539458]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Prédiction 80: [0.34970874]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 81: [0.32966575]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 82: [0.32010382]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 83: [0.3230575]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Prédiction 84: [0.33638734]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prédiction 85: [0.35435215]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 86: [0.37000462]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 87: [0.3778978]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 88: [0.3755202]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 89: [0.3631416]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 90: [0.3429553]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 91: [0.31848484]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Prédiction 92: [0.294361]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 93: [0.2757889]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 94: [0.26717013]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 95: [0.2702599]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 96: [0.28301138]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 97: [0.30011612]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 98: [0.31514227]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 99: [0.32297406]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prédiction 100: [0.32116956]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prédiction 101: [0.3099149]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Prédiction 102: [0.29129824]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Prédiction 103: [0.26872635]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Prédiction 104: [0.24659774]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Prédiction 105: [0.22971462]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Prédiction 106: [0.22203368]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 107: [0.22508709]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Prédiction 108: [0.23701668]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Prédiction 109: [0.2530528]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Prédiction 110: [0.26736626]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Prédiction 111: [0.27522096]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Prédiction 112: [0.27424738]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 113: [0.26450956]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prédiction 114: [0.24791744]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 115: [0.22766557]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prédiction 116: [0.20783193]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 117: [0.19276801]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "Prédictions finales (échelle originale):\n",
      "[[228815.73738915]\n",
      " [232511.4967289 ]\n",
      " [237033.32675743]\n",
      " [239750.90862697]\n",
      " [240492.68473828]\n",
      " [238602.65200448]\n",
      " [234778.16382587]\n",
      " [230355.71315396]\n",
      " [223274.77228945]\n",
      " [217298.0233978 ]\n",
      " [211687.05152446]\n",
      " [210738.66245043]\n",
      " [213815.5300321 ]\n",
      " [217840.48637825]\n",
      " [222141.90075564]\n",
      " [224988.69657946]\n",
      " [225531.20576137]\n",
      " [223675.57002014]\n",
      " [219821.18949205]\n",
      " [214516.77590603]\n",
      " [208441.24827683]\n",
      " [202913.91261005]\n",
      " [199312.00000119]\n",
      " [198862.27491641]\n",
      " [201304.70394617]\n",
      " [205345.27638835]\n",
      " [209345.27239168]\n",
      " [211800.00256217]\n",
      " [211982.04789454]\n",
      " [209885.54080242]\n",
      " [205913.08087373]\n",
      " [200658.03355575]\n",
      " [194949.76139182]\n",
      " [189970.28272682]\n",
      " [187019.16398937]\n",
      " [186923.1804406 ]\n",
      " [189455.65613055]\n",
      " [193391.67465174]\n",
      " [197084.74275601]\n",
      " [199191.84153455]\n",
      " [199088.26939476]\n",
      " [196800.85783887]\n",
      " [192735.78706855]\n",
      " [187513.25403333]\n",
      " [182007.02088684]\n",
      " [177382.05763245]\n",
      " [174831.36701393]\n",
      " [175020.85078257]\n",
      " [177639.54996127]\n",
      " [181463.48372227]\n",
      " [184924.16999531]\n",
      " [186781.27263314]\n",
      " [186469.89784282]\n",
      " [184034.89569896]\n",
      " [179891.65204561]\n",
      " [174688.75463408]\n",
      " [169332.26044381]\n",
      " [164970.47229874]\n",
      " [162706.27698028]\n",
      " [163089.70295918]\n",
      " [165745.66362143]\n",
      " [169467.05322528]\n",
      " [172755.80073696]\n",
      " [174441.58833325]\n",
      " [173996.88765806]\n",
      " [171477.68333966]\n",
      " [167309.98755962]\n",
      " [162166.57453752]\n",
      " [156970.83835346]\n",
      " [152841.30498558]\n",
      " [150797.77942634]\n",
      " [151302.65751296]\n",
      " [153947.33346677]\n",
      " [157560.2073738 ]\n",
      " [160713.13412136]\n",
      " [162293.37446511]\n",
      " [161797.63271868]\n",
      " [159284.76955169]\n",
      " [155185.89085752]\n",
      " [150187.08842874]\n",
      " [145209.60797721]\n",
      " [141325.61808363]\n",
      " [139472.67935306]\n",
      " [140045.05200854]\n",
      " [142628.14718133]\n",
      " [146109.42198333]\n",
      " [149142.60607746]\n",
      " [150672.16918653]\n",
      " [150211.43082693]\n",
      " [147812.66795915]\n",
      " [143900.90520841]\n",
      " [139158.9482879 ]\n",
      " [134484.1567508 ]\n",
      " [130885.20103586]\n",
      " [129215.02953559]\n",
      " [129813.77167866]\n",
      " [132284.79364163]\n",
      " [135599.40242475]\n",
      " [138511.21526372]\n",
      " [140028.88149491]\n",
      " [139679.19991285]\n",
      " [137498.23653811]\n",
      " [133890.64692393]\n",
      " [129516.59806442]\n",
      " [125228.44928339]\n",
      " [121956.78765191]\n",
      " [120468.3525117 ]\n",
      " [121060.05181856]\n",
      " [123371.80288506]\n",
      " [126479.3309156 ]\n",
      " [129253.03601781]\n",
      " [130775.14336506]\n",
      " [130586.47967246]\n",
      " [128699.45580924]\n",
      " [125484.18595645]\n",
      " [121559.71780214]\n",
      " [117716.29568462]\n",
      " [114797.16280064]]\n"
     ]
    }
   ],
   "source": [
    "# FORECAST USING RNN MODEL\n",
    "\n",
    "test_predictions = []\n",
    "first_eval_batch = train_scaled[-n_input:]\n",
    "current_batch = first_eval_batch.reshape((1, n_input, n_features))\n",
    "\n",
    "for i in range(len(test)):\n",
    "    # Obtenir la prédiction actuelle\n",
    "    current_pred = model.predict(current_batch)[0]\n",
    "\n",
    "    # Ajouter la prédiction à la liste des prédictions\n",
    "    test_predictions.append(current_pred)\n",
    "\n",
    "    # Mettre à jour le lot pour inclure la nouvelle prédiction\n",
    "    current_batch = np.append(current_batch[:, 1:, :], [[current_pred]], axis=1)\n",
    "\n",
    "    # Imprimez pour comprendre les dimensions et les valeurs\n",
    "    print(f\"Prédiction {i}: {current_pred}\")\n",
    "    print(f\"Dimensions actuelles du lot: {current_batch.shape}\")\n",
    "\n",
    "# Appliquer la transformation inverse pour obtenir les valeurs originales\n",
    "test_predictions_original = scaler.inverse_transform(test_predictions)\n",
    "\n",
    "# Imprimer les prédictions finales\n",
    "print(\"Prédictions finales (échelle originale):\")\n",
    "print(test_predictions_original)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_original = scaler.inverse_transform(test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assurez-vous que la partie mise à l'échelle de test commence à partir de l'indice 'n_input'\n",
    "y_test_original = scaler.inverse_transform(test_scaled[n_input:])\n",
    "\n",
    "# Comparez maintenant 'y_test_original' avec 'test_predictions_original'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [106, 118]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, mean_absolute_error\n\u001b[1;32m----> 3\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test_original, test_predictions_original)\n\u001b[0;32m      4\u001b[0m mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_test_original, test_predictions_original)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Squared Error (MSE):\u001b[39m\u001b[38;5;124m\"\u001b[39m, mse)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:474\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    405\u001b[0m     {\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    415\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    416\u001b[0m ):\n\u001b[0;32m    417\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;124;03m    0.825...\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 474\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    475\u001b[0m         y_true, y_pred, multioutput\n\u001b[0;32m    476\u001b[0m     )\n\u001b[0;32m    477\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    478\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:99\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m        correct keyword.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m    100\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    101\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    412\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [106, 118]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(y_test_original, test_predictions_original)\n",
    "mae = mean_absolute_error(y_test_original, test_predictions_original)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
