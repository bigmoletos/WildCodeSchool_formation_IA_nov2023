{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations nécessaires\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.initializers import GlorotUniform\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_csv('Miles_Traveled.csv')\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df.set_index('DATE', inplace=True)\n",
    "df = df.resample('MS').mean()\n",
    "df = df.fillna(method='ffill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.initializers import GlorotUniform\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "458/458 [==============================] - 5s 5ms/step - loss: 0.0105\n",
      "Epoch 2/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0058\n",
      "Epoch 3/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0038\n",
      "Epoch 4/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0035\n",
      "Epoch 5/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0022\n",
      "Epoch 6/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0027\n",
      "Epoch 7/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0027\n",
      "Epoch 8/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0023\n",
      "Epoch 9/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0023\n",
      "Epoch 10/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0025\n",
      "Epoch 11/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0026\n",
      "Epoch 12/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0027\n",
      "Epoch 13/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0025\n",
      "Epoch 14/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0022\n",
      "Epoch 15/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0020\n",
      "Epoch 16/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0023\n",
      "Epoch 17/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0027\n",
      "Epoch 18/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0025\n",
      "Epoch 19/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0022\n",
      "Epoch 20/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0021\n",
      "Epoch 21/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0022\n",
      "Epoch 22/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0022\n",
      "Epoch 23/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0021\n",
      "Epoch 24/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0023\n",
      "Epoch 25/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0020\n",
      "Epoch 26/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0018\n",
      "Epoch 27/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0022\n",
      "Epoch 28/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0020\n",
      "Epoch 29/30\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.0020\n",
      "Epoch 30/30\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.0020\n",
      "106/106 [==============================] - 1s 1ms/step\n",
      "Mean Squared Error (MSE): 284870928.90005666\n",
      "Mean Absolute Percentage Error (MAPE): 0.05741670231100586\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configuration des données\n",
    "n_input = 12\n",
    "n_features = 1\n",
    "\n",
    "# Séparer les données en ensembles d'entraînement et de test\n",
    "train_size = int(len(df) * 0.8)\n",
    "train, test = df.iloc[:train_size], df.iloc[train_size:]\n",
    "\n",
    "# Mise à l'échelle des données\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "test_scaled = scaler.transform(test)\n",
    "\n",
    "# Création du générateur de séries temporelles\n",
    "train_generator = TimeseriesGenerator(\n",
    "    train_scaled, train_scaled, length=n_input, batch_size=1)\n",
    "\n",
    "# Création du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(150, activation='tanh', input_shape=(\n",
    "    n_input, n_features), kernel_initializer=GlorotUniform()))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "history = model.fit(train_generator, epochs=30)\n",
    "\n",
    "# Prédictions\n",
    "test_generator = TimeseriesGenerator(\n",
    "    test_scaled, test_scaled, length=n_input, batch_size=1)\n",
    "y_pred = model.predict(test_generator)\n",
    "\n",
    "# Inverser la mise à l'échelle pour obtenir les vraies valeurs\n",
    "y_pred_original = scaler.inverse_transform(y_pred)\n",
    "y_test_original = scaler.inverse_transform(test_scaled[n_input:])\n",
    "\n",
    "# Calcul des métriques\n",
    "mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "mape = mean_absolute_percentage_error(y_test_original, y_pred_original)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder l'architecture du modèle au format JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_LSTM.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Sauvegarder les poids du modèle au format HDF5\n",
    "model.save_weights(\"model_LSTM_weights.h5\")\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Charger l'architecture du modèle à partir du fichier JSON\n",
    "with open(\"model_LSTM.json\", \"r\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Charger les poids du modèle à partir du fichier HDF5\n",
    "loaded_model.load_weights(\"model_LSTM_weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 858ms/step\n"
     ]
    }
   ],
   "source": [
    "# Sélectionnez les derniers points de données de l'ensemble d'entraînement\n",
    "first_eval_batch = train_scaled[-n_input:]\n",
    "\n",
    "# Redimensionnez le lot pour correspondre au format attendu par le modèle\n",
    "# Le nouveau format doit être [1, n_input, n_features]\n",
    "first_eval_batch = first_eval_batch.reshape((1, n_input, n_features))\n",
    "\n",
    "# Maintenant, vous pouvez utiliser ce lot pour faire une première prédiction\n",
    "first_pred = model.predict(first_eval_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "First test prediction (original scale): [[228815.75]]\n"
     ]
    }
   ],
   "source": [
    "# Sélectionnez les derniers points de données de l'ensemble d'entraînement\n",
    "last_train_batch = train_scaled[-n_input:]\n",
    "\n",
    "# Redimensionnez le lot pour correspondre au format attendu par le modèle\n",
    "# Le format doit être [1, n_input, n_features]\n",
    "last_train_batch = last_train_batch.reshape((1, n_input, n_features))\n",
    "\n",
    "# Faire la prédiction pour le premier point de l'ensemble de test\n",
    "first_test_prediction = model.predict(last_train_batch)\n",
    "\n",
    "# Appliquer la transformation inverse pour obtenir la valeur originale\n",
    "first_test_prediction_original = scaler.inverse_transform(first_test_prediction)\n",
    "\n",
    "print(\"First test prediction (original scale):\", first_test_prediction_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 0: [0.78115076]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Prédiction 1: [0.8002224]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Prédiction 2: [0.8235569]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 3: [0.83758074]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Prédiction 4: [0.8414086]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Prédiction 5: [0.83165526]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 6: [0.81191933]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 7: [0.78909767]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 8: [0.7525571]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 9: [0.7217146]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 10: [0.6927597]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 11: [0.6878656]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 12: [0.7037435]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 13: [0.72451395]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prédiction 14: [0.746711]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 15: [0.76140165]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 16: [0.7642012]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 17: [0.7546254]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 18: [0.7347352]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 19: [0.70736223]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 20: [0.67601]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 21: [0.6474867]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Prédiction 22: [0.62889934]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prédiction 23: [0.62657857]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 24: [0.6391825]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 25: [0.6600335]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 26: [0.68067515]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 27: [0.69334257]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 28: [0.694282]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Prédiction 29: [0.68346316]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Prédiction 30: [0.6629636]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 31: [0.6358454]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 32: [0.6063884]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prédiction 33: [0.58069223]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 34: [0.56546324]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Prédiction 35: [0.56496793]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 36: [0.57803655]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 37: [0.598348]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 38: [0.6174058]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prédiction 39: [0.62827927]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 40: [0.6277448]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 41: [0.6159408]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Prédiction 42: [0.5949634]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 43: [0.56801295]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 44: [0.5395985]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 45: [0.5157318]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 46: [0.5025692]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 47: [0.503547]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 48: [0.5170606]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 49: [0.53679365]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prédiction 50: [0.5546522]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 51: [0.5642356]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Prédiction 52: [0.5626288]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 53: [0.5500632]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 54: [0.52868235]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prédiction 55: [0.50183326]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prédiction 56: [0.47419155]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Prédiction 57: [0.45168293]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 58: [0.43999875]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 59: [0.44197738]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prédiction 60: [0.45568323]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prédiction 61: [0.47488713]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Prédiction 62: [0.49185842]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 63: [0.5005578]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 64: [0.49826294]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 65: [0.4852628]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 66: [0.4637558]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prédiction 67: [0.43721366]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 68: [0.41040152]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Prédiction 69: [0.38909143]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 70: [0.378546]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Prédiction 71: [0.38115138]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Prédiction 72: [0.394799]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Prédiction 73: [0.4134429]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 74: [0.4297133]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 75: [0.437868]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 76: [0.43530977]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Prédiction 77: [0.42234236]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 78: [0.40119046]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Prédiction 79: [0.37539458]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Prédiction 80: [0.34970874]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 81: [0.32966575]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 82: [0.32010382]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 83: [0.3230575]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Prédiction 84: [0.33638734]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prédiction 85: [0.35435215]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 86: [0.37000462]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 87: [0.3778978]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 88: [0.3755202]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 89: [0.3631416]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 90: [0.3429553]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 91: [0.31848484]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Prédiction 92: [0.294361]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 93: [0.2757889]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 94: [0.26717013]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 95: [0.2702599]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 96: [0.28301138]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 97: [0.30011612]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 98: [0.31514227]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 99: [0.32297406]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prédiction 100: [0.32116956]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prédiction 101: [0.3099149]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Prédiction 102: [0.29129824]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Prédiction 103: [0.26872635]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Prédiction 104: [0.24659774]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Prédiction 105: [0.22971462]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Prédiction 106: [0.22203368]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prédiction 107: [0.22508709]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Prédiction 108: [0.23701668]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Prédiction 109: [0.2530528]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Prédiction 110: [0.26736626]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Prédiction 111: [0.27522096]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Prédiction 112: [0.27424738]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prédiction 113: [0.26450956]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prédiction 114: [0.24791744]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prédiction 115: [0.22766557]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prédiction 116: [0.20783193]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prédiction 117: [0.19276801]\n",
      "Dimensions actuelles du lot: (1, 12, 1)\n",
      "Prédictions finales (échelle originale):\n",
      "[[228815.73738915]\n",
      " [232511.4967289 ]\n",
      " [237033.32675743]\n",
      " [239750.90862697]\n",
      " [240492.68473828]\n",
      " [238602.65200448]\n",
      " [234778.16382587]\n",
      " [230355.71315396]\n",
      " [223274.77228945]\n",
      " [217298.0233978 ]\n",
      " [211687.05152446]\n",
      " [210738.66245043]\n",
      " [213815.5300321 ]\n",
      " [217840.48637825]\n",
      " [222141.90075564]\n",
      " [224988.69657946]\n",
      " [225531.20576137]\n",
      " [223675.57002014]\n",
      " [219821.18949205]\n",
      " [214516.77590603]\n",
      " [208441.24827683]\n",
      " [202913.91261005]\n",
      " [199312.00000119]\n",
      " [198862.27491641]\n",
      " [201304.70394617]\n",
      " [205345.27638835]\n",
      " [209345.27239168]\n",
      " [211800.00256217]\n",
      " [211982.04789454]\n",
      " [209885.54080242]\n",
      " [205913.08087373]\n",
      " [200658.03355575]\n",
      " [194949.76139182]\n",
      " [189970.28272682]\n",
      " [187019.16398937]\n",
      " [186923.1804406 ]\n",
      " [189455.65613055]\n",
      " [193391.67465174]\n",
      " [197084.74275601]\n",
      " [199191.84153455]\n",
      " [199088.26939476]\n",
      " [196800.85783887]\n",
      " [192735.78706855]\n",
      " [187513.25403333]\n",
      " [182007.02088684]\n",
      " [177382.05763245]\n",
      " [174831.36701393]\n",
      " [175020.85078257]\n",
      " [177639.54996127]\n",
      " [181463.48372227]\n",
      " [184924.16999531]\n",
      " [186781.27263314]\n",
      " [186469.89784282]\n",
      " [184034.89569896]\n",
      " [179891.65204561]\n",
      " [174688.75463408]\n",
      " [169332.26044381]\n",
      " [164970.47229874]\n",
      " [162706.27698028]\n",
      " [163089.70295918]\n",
      " [165745.66362143]\n",
      " [169467.05322528]\n",
      " [172755.80073696]\n",
      " [174441.58833325]\n",
      " [173996.88765806]\n",
      " [171477.68333966]\n",
      " [167309.98755962]\n",
      " [162166.57453752]\n",
      " [156970.83835346]\n",
      " [152841.30498558]\n",
      " [150797.77942634]\n",
      " [151302.65751296]\n",
      " [153947.33346677]\n",
      " [157560.2073738 ]\n",
      " [160713.13412136]\n",
      " [162293.37446511]\n",
      " [161797.63271868]\n",
      " [159284.76955169]\n",
      " [155185.89085752]\n",
      " [150187.08842874]\n",
      " [145209.60797721]\n",
      " [141325.61808363]\n",
      " [139472.67935306]\n",
      " [140045.05200854]\n",
      " [142628.14718133]\n",
      " [146109.42198333]\n",
      " [149142.60607746]\n",
      " [150672.16918653]\n",
      " [150211.43082693]\n",
      " [147812.66795915]\n",
      " [143900.90520841]\n",
      " [139158.9482879 ]\n",
      " [134484.1567508 ]\n",
      " [130885.20103586]\n",
      " [129215.02953559]\n",
      " [129813.77167866]\n",
      " [132284.79364163]\n",
      " [135599.40242475]\n",
      " [138511.21526372]\n",
      " [140028.88149491]\n",
      " [139679.19991285]\n",
      " [137498.23653811]\n",
      " [133890.64692393]\n",
      " [129516.59806442]\n",
      " [125228.44928339]\n",
      " [121956.78765191]\n",
      " [120468.3525117 ]\n",
      " [121060.05181856]\n",
      " [123371.80288506]\n",
      " [126479.3309156 ]\n",
      " [129253.03601781]\n",
      " [130775.14336506]\n",
      " [130586.47967246]\n",
      " [128699.45580924]\n",
      " [125484.18595645]\n",
      " [121559.71780214]\n",
      " [117716.29568462]\n",
      " [114797.16280064]]\n"
     ]
    }
   ],
   "source": [
    "# FORECAST USING RNN MODEL\n",
    "\n",
    "test_predictions = []\n",
    "first_eval_batch = train_scaled[-n_input:]\n",
    "current_batch = first_eval_batch.reshape((1, n_input, n_features))\n",
    "\n",
    "for i in range(len(test)):\n",
    "    # Obtenir la prédiction actuelle\n",
    "    current_pred = model.predict(current_batch)[0]\n",
    "\n",
    "    # Ajouter la prédiction à la liste des prédictions\n",
    "    test_predictions.append(current_pred)\n",
    "\n",
    "    # Mettre à jour le lot pour inclure la nouvelle prédiction\n",
    "    current_batch = np.append(current_batch[:, 1:, :], [[current_pred]], axis=1)\n",
    "\n",
    "    # Imprimez pour comprendre les dimensions et les valeurs\n",
    "    print(f\"Prédiction {i}: {current_pred}\")\n",
    "    print(f\"Dimensions actuelles du lot: {current_batch.shape}\")\n",
    "\n",
    "# Appliquer la transformation inverse pour obtenir les valeurs originales\n",
    "test_predictions_original = scaler.inverse_transform(test_predictions)\n",
    "\n",
    "# Imprimer les prédictions finales\n",
    "print(\"Prédictions finales (échelle originale):\")\n",
    "print(test_predictions_original)\n",
    "\n",
    "\n",
    "test_predictions_original = scaler.inverse_transform(test_predictions)\n",
    "\n",
    "# Assurez-vous que la partie mise à l'échelle de test commence à partir de l'indice 'n_input'\n",
    "y_test_original = scaler.inverse_transform(test_scaled[n_input:])\n",
    "\n",
    "# Comparez maintenant 'y_test_original' avec 'test_predictions_original'\n",
    "\n",
    "# Tronquer test_scaled pour correspondre à la longueur des prédictions\n",
    "# Assurez-vous que la longueur de test_scaled est égale à n_input + longueur de y_test_original_truncated\n",
    "test_scaled_adjusted = test_scaled[-(n_input + len(y_test_original_truncated)):]\n",
    "\n",
    "# Générer les prédictions en utilisant test_scaled_adjusted\n",
    "# Votre code de prédiction ici...\n",
    "\n",
    "# Assurez-vous maintenant que la longueur des prédictions correspond à celle de y_test_original_truncated\n",
    "test_predictions_adjusted = test_predictions_original[-len(y_test_original_truncated):]\n",
    "\n",
    "# Calculer les métriques\n",
    "mse = mean_squared_error(y_test_original_truncated, test_predictions_adjusted)\n",
    "mae = mean_absolute_error(y_test_original_truncated, test_predictions_adjusted)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Real Values    Predictions\n",
      "0       254238.0  213815.530032\n",
      "1       253936.0  217840.486378\n",
      "2       256927.0  222141.900756\n",
      "3       260083.0  224988.696579\n",
      "4       265315.0  225531.205761\n",
      "..           ...            ...\n",
      "101     286608.0  128699.455809\n",
      "102     260595.0  125484.185956\n",
      "103     282174.0  121559.717802\n",
      "104     258590.0  117716.295685\n",
      "105     268413.0  114797.162801\n",
      "\n",
      "[106 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ajuster la longueur de test_predictions_original pour qu'elle corresponde à celle de y_test_original\n",
    "test_predictions_adjusted = test_predictions_original[-len(y_test_original):]\n",
    "\n",
    "# Créer un DataFrame avec les valeurs réelles et les prédictions\n",
    "results_df = pd.DataFrame({\n",
    "    'Real Values': y_test_original.ravel(),  # Convertir en un tableau 1D si nécessaire\n",
    "    'Predictions': test_predictions_adjusted.ravel()  # De même, convertir en 1D si nécessaire\n",
    "})\n",
    "\n",
    "print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
