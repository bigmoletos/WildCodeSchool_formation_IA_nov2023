{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow import keras\n",
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "# Charger l'ensemble de données Fashion MNIST\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "# Listes d'hyperparamètres\n",
    "nombre_epochs = 50\n",
    "taux_apprentissage = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [64, 128, 256]\n",
    "architectures_couches = [[64], [128], [64, 64], [128, 64]]\n",
    "taux_dropout = [0.2, 0.3, 0.5]\n",
    "fonctions_perte = ['sparse_categorical_crossentropy', 'categorical_crossentropy', 'binary_crossentropy', 'mean_squared_error', 'mean_absolute_error', 'kullback_leibler_divergence', 'poisson', 'cosine_similarity']\n",
    "optimiseurs = [keras.optimizers.Adam, keras.optimizers.SGD, keras.optimizers.RMSprop, keras.optimizers.Adagrad, keras.optimizers.Adadelta, keras.optimizers.Nadam, keras.optimizers.Ftrl]\n",
    "fonctions_activation = ['relu', 'sigmoid', 'tanh', 'softmax']\n",
    "\n",
    "meilleurs_resultats = []\n",
    "meilleure_accuracy = 0\n",
    "\n",
    "for lr in taux_apprentissage:\n",
    "    for batch_size in batch_sizes:\n",
    "        for architecture in architectures_couches:\n",
    "            for dropout in taux_dropout:\n",
    "                for loss_function in fonctions_perte:\n",
    "                    for Optimizer in optimiseurs:\n",
    "                        for activation_function in fonctions_activation:\n",
    "                            # Construction du modèle\n",
    "                            net = keras.models.Sequential()\n",
    "                            net.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "                            for neurones in architecture:\n",
    "                                net.add(keras.layers.Dense(neurones, activation=activation_function))\n",
    "                                net.add(keras.layers.Dropout(dropout))\n",
    "                            net.add(keras.layers.Dense(10, activation='softmax'))  # softmax pour classification\n",
    "\n",
    "                            # Compilation du modèle\n",
    "                            optimizer = Optimizer(learning_rate=lr)\n",
    "                            net.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
    "\n",
    "                            # Callback pour l'arrêt prématuré\n",
    "                            early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "                            # Entraînement du modèle\n",
    "                            history = net.fit(X_train, y_train, epochs=nombre_epochs, batch_size=batch_size, validation_split=0.2, callbacks=[early_stopping_cb], verbose=0)\n",
    "\n",
    "                            # Évaluer la performance du modèle\n",
    "                            current_accuracy = max(history.history['val_accuracy'])\n",
    "\n",
    "                            # Comparer et stocker le meilleur résultat\n",
    "                            if current_accuracy > meilleure_accuracy:\n",
    "                                meilleure_accuracy = current_accuracy\n",
    "                                meilleurs_resultats = [\n",
    "                                    ('taux_apprentissage', lr),\n",
    "                                    ('batch_size', batch_size),\n",
    "                                    ('architecture', architecture),\n",
    "                                    ('dropout', dropout),\n",
    "                                    ('fonction_perte', loss_function),\n",
    "                                    ('optimiseur', Optimizer.__name__),\n",
    "                                    ('fonction_activation', activation_function),\n",
    "                                    ('accuracy', meilleure_accuracy)\n",
    "                                ]\n",
    "                            # Afficher les meilleurs hyperparamètres\n",
    "                            print(\"Meilleurs hyperparamètres : \", meilleurs_resultats)\n",
    "\n",
    "# Afficher les meilleurs hyperparamètres\n",
    "print(\"Meilleurs hyperparamètres : \", meilleurs_resultats)\n",
    "nd_time = time.perf_counter()\n",
    "duration = end_time - start_time\n",
    "print(f\"Temps d'exécution du script: {duration} secondes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
