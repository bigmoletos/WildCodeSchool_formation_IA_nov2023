{"cells":[{"cell_type":"markdown","metadata":{"id":"CZBFjNu331pr"},"source":["# Function to automatic merge and fill missing values\n"]},{"cell_type":"markdown","metadata":{"id":"5sBNQ8Wl39Pk"},"source":["\n","## Create the function\n","You have to create a function which take 2 arguments :\n","- argument 1 : DataFrame main\n","- argument 2 : DataFrame opinion\n","\n","Your function will return a new DataFrame which is the left merge of both DataFrames, and which has no missing values (so your function has to fill them), add new columns (flag, MONTH and DAY), and OPINION should be translated.\n","\n","So you have to copy each useful code from the previous quests, and integrate it into a function. **This should achieve the same results as the previous quests.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uy9gkxw44znE"},"outputs":[],"source":["import pandas as pd\n","link_main = \"https://raw.githubusercontent.com/WildCodeSchool/data-training-resources/main/quests/weather_main_2018.csv\"\n","link_opinion = \"https://raw.githubusercontent.com/WildCodeSchool/data-training-resources/main/quests/weather_opinion_2018.csv\"\n","df_main = pd.read_csv(link_main)\n","df_opinion = pd.read_csv(link_opinion)\n","print(df_main.head())\n","print(df_opinion.head())"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[],"source":["def create_df_wild_with2date(start_year, end_year):\n","    import pandas as pd\n","    # Initiate an empty DataFrame\n","    dftotal = pd.DataFrame()\n","    # Collect both DataFrames each year\n","    plage_year = [year for year in range(start_year, end_year)]\n","\n","    for var_year in plage_year:\n","        year = str(var_year)\n","        link_main = \"https://raw.githubusercontent.com/WildCodeSchool/data-training-resources/main/quests/weather_main_\" + year + \".csv\"\n","        link_opinion = \"https://raw.githubusercontent.com/WildCodeSchool/data-training-resources/main/quests/weather_opinion_\" + year + \".csv\"\n","        df_main = pd.read_csv(link_main)\n","        df_opinion = pd.read_csv(link_opinion)\n","    # Apply your merge, cleaning and fillna function on the current year\n","    df_year = mergeDF(df_main, df_opinion)\n","\n","    # Concat with the global DF\n","    dftotal = pd.concat([dftotal, df_year])\n","    return dftotal\n","\n","\n","def mergeDF(df_main, df_opinion):\n","    dfnew = pd.merge(left=df_main,\n","                     right=df_opinion,\n","                     left_on='DATE',\n","                     right_on=\"date\",\n","                     how='left')\n","    return dfnew"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["dftotal = create_df_wild_with2date(2017, 2019)"]},{"cell_type":"markdown","metadata":{},"source":["### INFOS SUR LE DATASET"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["# INFOS SUR LE DATASET\n","\"\"\"fonction resumant les informations essentielles Ã  connaittre sur un dataset\n","\"\"\"\n","\n","\n","def info_dataframe(dataframe):\n","    df = dataframe\n","    print(\"\\ntaille: \", df.size, \"valeurs.\", \" \\nDimensions:\", df.shape)\n","    print(\"\\nNombre de na:\", df.isna().all().size,\n","          \"\\nNombre de null:\", df.isnull().all().size)\n","    print(\"\\nliste nom des colonnes: \\n\", df.columns)\n","    print(\"\\nliste colonnes comportant des NA: \\n\", df[df.isna()].columns)\n","    try:\n","        print(\"\\nliste nom des valeurs uniques par ligne: \\n\",\n","              df[df.iloc[:, 1:]].value.unique())\n","        for col in df.columns[1:]:\n","            if df[col].dtype == 'object' and df[col].dtype != 'int*' and df[col].dtype != 'float*':\n","                print(f\"\\nValeurs uniques pour {col} : \\n\", df[col].unique())\n","    except:\n","        print(\"\\nil y a trop de colonnes pour sortir les valeurs uniques de chacunes\\n\")\n","        # pass\n","    print(\"\\nInfo\")\n","    print(df.info())\n","    print(\"\\nDescribe\")\n","    print(df.describe())\n","    print(\"\\nHead\")\n","    print(df.head(5))\n","    return"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","taille:  7665 valeurs.  \n","Dimensions: (365, 21)\n","\n","Nombre de na: 21 \n","Nombre de null: 21\n","\n","liste nom des colonnes: \n"," Index(['DATE', 'MAX_TEMPERATURE_C', 'MIN_TEMPERATURE_C', 'WINDSPEED_MAX_KMH',\n","       'TEMPERATURE_MORNING_C', 'TEMPERATURE_NOON_C', 'TEMPERATURE_EVENING_C',\n","       'PRECIP_TOTAL_DAY_MM', 'HUMIDITY_MAX_PERCENT', 'VISIBILITY_AVG_KM',\n","       'PRESSURE_MAX_MB', 'CLOUDCOVER_AVG_PERCENT', 'HEATINDEX_MAX_C',\n","       'DEWPOINT_MAX_C', 'WINDTEMP_MAX_C', 'date', 'WEATHER_CODE_EVENING',\n","       'TOTAL_SNOW_MM', 'UV_INDEX', 'SUNHOUR', 'OPINION'],\n","      dtype='object')\n","\n","liste colonnes comportant des NA: \n"," Index(['DATE', 'MAX_TEMPERATURE_C', 'MIN_TEMPERATURE_C', 'WINDSPEED_MAX_KMH',\n","       'TEMPERATURE_MORNING_C', 'TEMPERATURE_NOON_C', 'TEMPERATURE_EVENING_C',\n","       'PRECIP_TOTAL_DAY_MM', 'HUMIDITY_MAX_PERCENT', 'VISIBILITY_AVG_KM',\n","       'PRESSURE_MAX_MB', 'CLOUDCOVER_AVG_PERCENT', 'HEATINDEX_MAX_C',\n","       'DEWPOINT_MAX_C', 'WINDTEMP_MAX_C', 'date', 'WEATHER_CODE_EVENING',\n","       'TOTAL_SNOW_MM', 'UV_INDEX', 'SUNHOUR', 'OPINION'],\n","      dtype='object')\n","\n","il y a trop de colonnes pour sortir les valeurs uniques de chacunes\n","\n","\n","Info\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 365 entries, 0 to 364\n","Data columns (total 21 columns):\n"," #   Column                  Non-Null Count  Dtype  \n","---  ------                  --------------  -----  \n"," 0   DATE                    365 non-null    object \n"," 1   MAX_TEMPERATURE_C       365 non-null    int64  \n"," 2   MIN_TEMPERATURE_C       365 non-null    int64  \n"," 3   WINDSPEED_MAX_KMH       365 non-null    int64  \n"," 4   TEMPERATURE_MORNING_C   365 non-null    int64  \n"," 5   TEMPERATURE_NOON_C      365 non-null    int64  \n"," 6   TEMPERATURE_EVENING_C   365 non-null    int64  \n"," 7   PRECIP_TOTAL_DAY_MM     365 non-null    float64\n"," 8   HUMIDITY_MAX_PERCENT    365 non-null    int64  \n"," 9   VISIBILITY_AVG_KM       365 non-null    float64\n"," 10  PRESSURE_MAX_MB         365 non-null    int64  \n"," 11  CLOUDCOVER_AVG_PERCENT  365 non-null    float64\n"," 12  HEATINDEX_MAX_C         365 non-null    int64  \n"," 13  DEWPOINT_MAX_C          365 non-null    int64  \n"," 14  WINDTEMP_MAX_C          365 non-null    int64  \n"," 15  date                    341 non-null    object \n"," 16  WEATHER_CODE_EVENING    341 non-null    float64\n"," 17  TOTAL_SNOW_MM           341 non-null    float64\n"," 18  UV_INDEX                341 non-null    float64\n"," 19  SUNHOUR                 341 non-null    float64\n"," 20  OPINION                 341 non-null    object \n","dtypes: float64(7), int64(11), object(3)\n","memory usage: 60.0+ KB\n","None\n","\n","Describe\n","       MAX_TEMPERATURE_C  MIN_TEMPERATURE_C  WINDSPEED_MAX_KMH  \\\n","count         365.000000         365.000000         365.000000   \n","mean           16.879452           9.315068          19.205479   \n","std             6.773959           5.339251           8.682050   \n","min             1.000000          -6.000000           4.000000   \n","25%            12.000000           6.000000          13.000000   \n","50%            16.000000           9.000000          18.000000   \n","75%            23.000000          14.000000          24.000000   \n","max            33.000000          21.000000          61.000000   \n","\n","       TEMPERATURE_MORNING_C  TEMPERATURE_NOON_C  TEMPERATURE_EVENING_C  \\\n","count             365.000000          365.000000             365.000000   \n","mean               10.263014           16.345205              13.863014   \n","std                 5.605323            6.749543               6.865896   \n","min                -6.000000            0.000000              -3.000000   \n","25%                 6.000000           11.000000               9.000000   \n","50%                10.000000           16.000000              13.000000   \n","75%                15.000000           22.000000              20.000000   \n","max                22.000000           32.000000              30.000000   \n","\n","       PRECIP_TOTAL_DAY_MM  HUMIDITY_MAX_PERCENT  VISIBILITY_AVG_KM  \\\n","count           365.000000            365.000000         365.000000   \n","mean              1.057808             78.123288           9.087329   \n","std               2.140100             11.995816           1.236827   \n","min               0.000000             32.000000           2.750000   \n","25%               0.000000             70.000000           8.375000   \n","50%               0.100000             79.000000           9.750000   \n","75%               1.100000             88.000000          10.000000   \n","max              15.300000             98.000000          10.000000   \n","\n","       PRESSURE_MAX_MB  CLOUDCOVER_AVG_PERCENT  HEATINDEX_MAX_C  \\\n","count       365.000000              365.000000       365.000000   \n","mean       1018.600000               42.601370        17.627397   \n","std           8.065937               28.511112         7.429398   \n","min         991.000000                0.000000         1.000000   \n","25%        1014.000000               17.000000        12.000000   \n","50%        1019.000000               41.125000        16.000000   \n","75%        1023.000000               65.750000        25.000000   \n","max        1039.000000              100.000000        36.000000   \n","\n","       DEWPOINT_MAX_C  WINDTEMP_MAX_C  WEATHER_CODE_EVENING  TOTAL_SNOW_MM  \\\n","count      365.000000      365.000000            341.000000          341.0   \n","mean        11.646575       12.378082            118.507331            0.0   \n","std          5.338387        8.031843             16.988338            0.0   \n","min          0.000000      -11.000000            113.000000            0.0   \n","25%          8.000000        6.000000            113.000000            0.0   \n","50%         12.000000       12.000000            116.000000            0.0   \n","75%         16.000000       19.000000            119.000000            0.0   \n","max         22.000000       30.000000            353.000000            0.0   \n","\n","         UV_INDEX     SUNHOUR  \n","count  341.000000  341.000000  \n","mean     1.574780    9.903519  \n","std      1.126346    3.543650  \n","min      1.000000    3.300000  \n","25%      1.000000    7.400000  \n","50%      1.000000   10.200000  \n","75%      1.000000   11.600000  \n","max      5.000000   16.000000  \n","\n","Head\n","         DATE  MAX_TEMPERATURE_C  MIN_TEMPERATURE_C  WINDSPEED_MAX_KMH  \\\n","0  2018-01-01                 12                  8                 61   \n","1  2018-01-02                 13                  6                 26   \n","2  2018-01-03                 15                 10                 40   \n","3  2018-01-04                 14                 11                 45   \n","4  2018-01-05                 12                  7                 21   \n","\n","   TEMPERATURE_MORNING_C  TEMPERATURE_NOON_C  TEMPERATURE_EVENING_C  \\\n","0                      9                  11                      8   \n","1                      8                  12                     13   \n","2                     11                  12                     10   \n","3                     14                  14                     11   \n","4                     10                  11                      8   \n","\n","   PRECIP_TOTAL_DAY_MM  HUMIDITY_MAX_PERCENT  VISIBILITY_AVG_KM  ...  \\\n","0                  8.9                    79              9.500  ...   \n","1                  0.6                    96              9.000  ...   \n","2                  5.5                    82              8.500  ...   \n","3                  0.0                    89             10.000  ...   \n","4                  1.5                    85              9.875  ...   \n","\n","   CLOUDCOVER_AVG_PERCENT  HEATINDEX_MAX_C  DEWPOINT_MAX_C  WINDTEMP_MAX_C  \\\n","0                  41.750               12               8               7   \n","1                  87.875               13              12               6   \n","2                  91.500               15              13               7   \n","3                  90.125               14              12              10   \n","4                  62.375               12              10               7   \n","\n","         date WEATHER_CODE_EVENING  TOTAL_SNOW_MM  UV_INDEX  SUNHOUR  OPINION  \n","0  2018-01-01                113.0            0.0       3.0      5.1      bad  \n","1  2018-01-02                122.0            0.0       3.0      3.3      bad  \n","2  2018-01-03                122.0            0.0       3.0      3.3      bad  \n","3  2018-01-04                116.0            0.0       3.0      3.3      bad  \n","4  2018-01-05                116.0            0.0       3.0      6.9      bad  \n","\n","[5 rows x 21 columns]\n"]}],"source":["# test fonction info\n","info_dataframe(dftotal)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# INFOS SUR LE DATASET\n","\n","# ONLY FEMALE\n","# Select a dataset with only female customers. Call it f_customers and keep only the 'Invoice ID', 'Unit price', and 'Quantity' columns.\n","# Check the shape of this subset\n","\n","f_customers = df.loc[df['Gender'] == 'Female',\n","                     ['Invoice ID', 'Unit price', 'Quantity']]\n","f_customers.shape\n","f_customers.head(3)\n","# Select a dataset with only male customers. Call it m_customer and keep only the 'Invoice ID', 'Unit price', and 'Quantity' columns.\n","# Check the shape of this subset\n","m_customers = df.loc[df['Gender'] == 'Male',\n","                     ['Invoice ID', 'Unit price', 'Quantity']]\n","m_customers.shape\n","# Now concat the 2 datasets. Before you start coding, what is the final shape of this dataset? Why?\n","# on s'attend Ã  un shape de (1000,3)\n","\n","\n","# Make sure to check if you are correct in your assumption.\n","\n","fm_customers = pd.concat([f_customers, m_customers], axis=0)\n","fm_customers.shape\n","# fm_customers.head(3)\n","# Select a dataset with only male customers. Call it m_customer_2 and keep only the 'Date', 'Time', and 'Payment' columns.\n","# Check the shape of this subset\n","m_customers_2 = df.loc[df['Gender'] == 'Male',\n","                       ['Date', 'Time', 'Payment']]\n","m_customers_2.shape\n","# Now concat the datasets m_customer and m_customer_2. Before you start coding, what is the final shape of this dataset? Why?\n","#  j'attends un shape de (499,6)\n","\n","\n","# Make sure to check if you are correct in your assumption.\n","\n","\n","pd.concat([m_customers, m_customers_2], axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["## MAKE A FUNCTION TO CREATE DATAFRAMES"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"njsItedL3utQ"},"outputs":[],"source":["# def merge_and_fill(DataFrameMain, DataFrameOpinion):\n","def add_col_and_fill(dftotal):\n","    df = dftotal\n","\n","\n","    # dÃ©ja intÃ©grÃ© dans la fonction create_df_wild_with2date()\n","    # MERGE\n","    # # Apply your merge, cleaning and fillna function on the current year\n","    # df_year = mergeDF(df_main , df_opinion)\n","    # # Concat with the global DF\n","    # dftotal = pd.concat([dftotal , df_year])\n","\n","    #  formatage colonne date en date\n","    df['DATE'] = pd.to_datetime(df['DATE'])\n","    df.set_index('DATE', inplace=True)\n","\n","    # FILL IN MISSING VALUES\n","    # remplacement de na par 0\n","    liste_colonnes_nulle = [\"TOTAL_SNOW_MM\", ]\n","    for column_name in liste_colonnes_nulle:\n","        df[column_name] = df[column_name].fillna(0, inplace=True)\n","\n","    # remplacement de na par la valeur mediane\n","    liste_colonnes_mediane = [\"WEATHER_CODE_EVENING\"]\n","    for column_name in liste_colonnes_mediane:\n","        median_value = df[column_name].median()\n","        df[column_name] = df[column_name].fillna(median_value, inplace=True)\n","    # \"UV_INDEX\"\n","    # remplacement de na par bfill et ffill\n","    liste_colonnes_mediane = [\"UV_INDEX\"]\n","    for column_name in liste_colonnes_mediane:\n","        df[column_name] = df[column_name].fillna(method='ffill', inplace=True)\n","        df[column_name] = df[column_name].fillna(method='bfill', inplace=True)\n","        # Remplir les valeurs manquantes restantes avec 0\n","        df[column_name] = df[column_name].fillna(0, inplace=True)\n","\n","    # \"OPINION\"\n","    # remplacement de na par unknown\n","    liste_colonnes_mediane = [\"OPINION\"]\n","    for column_name in liste_colonnes_mediane:\n","        df[column_name] = df[column_name].fillna(\"unknown\", inplace=True)\n","\n","\n","    # ADD NEW COLUMNS\n","    # colonne flag\n","    df['flag'] = df['OPINION'].isna()\n","    df['flag'].value_counts()\n","\n","\n","    # TRANSLATE OPINION\n","\n","    return NewDataFrame"]},{"cell_type":"markdown","metadata":{"id":"851Xnj1M4_xd"},"source":["## Execution with a loop\n","You will execute your function in a 9 rounds loop, once per year, and agregate this in a new big DataFrame with 24 columns and lots of rows."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AE09BUYX5blp"},"outputs":[],"source":["# Each year between 2010 and 2018 (included) has 2 sources : weather_main_YYYY.csv and weather_opinion_YYYY.csv\n","\n","for year in range(2010, 2019):\n","\n"]},{"cell_type":"markdown","metadata":{"id":"c5YtwMyw6BiW"},"source":["## Add 2019 to 2022"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pTiJ3fAa6FEC"},"outputs":[],"source":["# Each year since 2019 (included) has 1 source : weatherYYYY.csv\n","# Chaque annÃ©e depuis 2019 (inclus) a une seule source avec ce format de nom de fichier : weatherYYYY.csv\n","link2019 = \"https://raw.githubusercontent.com/WildCodeSchool/data-training-resources/main/quests/weather2019.csv\""]},{"cell_type":"markdown","metadata":{"id":"a2DO5esW6Weh"},"source":["# Draw a scatterplot\n","With Date on X-Axis and Max Temperature on Y-axis\n","\n","The result must have 13 seasonality for the 13 summers/winters alternance.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j7TKmTuSe1JP"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"MnFjmbITe0mS"},"source":["\n","Find appropriate dataviz to answer to this question :\n","\n","Which year had the best weather? Are years very different or not ?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fDneGuBle8cs"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## SOURCES"]},{"cell_type":"markdown","metadata":{},"source":["### Application des mÃªmes filtres et merge que pour la base df2018"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def filtre_and_fill(dataframe):\n","    df_2 = df.copy()\n","    # valeurs nulle de la colonne DATE\n","    # filtre_valeur_nulle = df[df.isna().any(axis=1) ]\n","    filtre_valeur_nulle = df['DATE'][df.isna().any(axis=1)].to_list()\n","    # df.loc[filtre_valeur_nulle,'DATE']\n","    print(\"Nombre de dates: \", len(filtre_valeur_nulle),\n","          \"\\nliste des dates dont les colonnes ont des valeurs nulles: \\n\", filtre_valeur_nulle)\n","\n","    # Just execute the code below :\n","    df['flag'] = df['OPINION'].isna()\n","    df['flag'].value_counts()\n","\n","    # filtre les lignes Ã  True de la colonne flag\n","    filtre_flag = df[df['flag'] == True]\n","    # filtre les noms des colonnescontenant des valeurs nulles en utilisant le filtre precedent\n","    noms_colonne_avec_des_na = filtre_flag.columns[filtre_flag.isna(\n","    ).any()].tolist()\n","    print(noms_colonne_avec_des_na)\n","\n","    #  formatage colonne date en date\n","    df_2['DATE'] = pd.to_datetime(df_2['DATE'])\n","    df_2.set_index('DATE', inplace=True)\n","\n","    # Hop ! Your code here :\n","\n","    mean_snow_column = df['WEATHER_CODE_EVENING'].mean()\n","    median_weather_column = df['WEATHER_CODE_EVENING'].median()\n","    print(mean_snow_column, median_weather_column)\n","    # je choisi la mÃ©diane qui me semble plus pertinente dans notre cas\n","    df['WEATHER_CODE_EVENING'].fillna(median_weather_column,\n","                                      inplace=True)  # When you are OK, you can replace this argument by True\n","    df['WEATHER_CODE_EVENING'].value_counts()\n","\n","    # You can use this code to check how many missing values you have :\n","    column_name = 'WEATHER_CODE_EVENING'\n","    print(\"I have \", df[column_name].isna().sum(),\n","          \"missing values in the column\", column_name)\n","\n","    # TOTAL_SNOW_MM\n","\n","    # You can use this code to check how many missing values you have :\n","    column_name = 'TOTAL_SNOW_MM'\n","    print(\"I have \", df[column_name].isna().sum(),\n","          \"missing values in the column\", column_name)\n","\n","    # test\n","    column_name = \"TOTAL_SNOW_MM\"\n","    mean_value = df[column_name].mean()\n","    min_value = df[column_name].min()\n","    median_value = df[column_name].median()\n","    max_value = df[column_name].max()\n","    print(mean_value, median_value, min_value, max_value)\n","    # comme il n'a pas neigÃ© Ã  cette pÃ©riode nous allons remplacÃ© les Nan par des o\n","  # nous faisons la mÃ©me chose pour la colonne index,\n","\n","    df[column_name] = df[column_name].fillna(0)\n","    print(\"I have \", df[column_name].isna().sum(),\n","          \"missing values in the column\", column_name)\n","\n","    # UV_INDEX\n","    column_name = \"UV_INDEX\"\n","    mean_value = df[column_name].mean()\n","    median_value = df[column_name].median()\n","    min_value = df[column_name].min()\n","    max_value = df[column_name].max()\n","    print(mean_value, median_value, min_value, max_value)\n","    # Nous faisons le choix de mettre l'index UV mÃ©dian\n","    df[column_name] = df[column_name].fillna(median_value)\n","\n","    # Your code here\n","    # UV_INDEX\n","    column_name = \"SUNHOUR\"\n","    mean_value = df[column_name].mean()\n","    median_value = df[column_name].median()\n","    min_value = df[column_name].min()\n","    max_value = df[column_name].max()\n","    print(mean_value, median_value, min_value, max_value)\n","    # Nous faisons le choix de mettre l'index UV mÃ©dian\n","    df[column_name] = df[column_name].fillna(method='ffill')\n","    df[column_name] = df[column_name].fillna(method='bfill')\n","    # Remplir les valeurs manquantes restantes avec 0\n","    df[column_name] = df[column_name].fillna(0)\n","    #  Verification\n","    print(\"I have \", df[column_name].isna().sum(),\n","          \"missing values in the column\", column_name)\n","\n","    # Your code here\n","    # OPINION\n","    column_name = \"OPINION\"\n","\n","    df[column_name] = df[column_name].fillna(\"unknown\")\n","\n","    #  Verification\n","    print(\"I have \", df[column_name].isna().sum(),\n","          \"missing values in the column\", column_name)\n","    return dataframe"]}],"metadata":{"colab":{"provenance":[{"file_id":"1xAOk19Y0JRq0UTdoYGEV40-pgRWQbC2f","timestamp":1701678466078}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
