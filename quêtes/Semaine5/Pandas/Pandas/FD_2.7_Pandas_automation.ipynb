{"cells":[{"cell_type":"markdown","metadata":{"id":"CZBFjNu331pr"},"source":["# Function to automatic merge and fill missing values\n"]},{"cell_type":"markdown","metadata":{"id":"5sBNQ8Wl39Pk"},"source":["\n","## Create the function\n","You have to create a function which take 2 arguments :\n","- argument 1 : DataFrame main\n","- argument 2 : DataFrame opinion\n","\n","Your function will return a new DataFrame which is the left merge of both DataFrames, and which has no missing values (so your function has to fill them), add new columns (flag, MONTH and DAY), and OPINION should be translated.\n","\n","So you have to copy each useful code from the previous quests, and integrate it into a function. **This should achieve the same results as the previous quests.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uy9gkxw44znE"},"outputs":[],"source":["import pandas as pd\n","link_main = \"https://raw.githubusercontent.com/WildCodeSchool/data-training-resources/main/quests/weather_main_2018.csv\"\n","link_opinion = \"https://raw.githubusercontent.com/WildCodeSchool/data-training-resources/main/quests/weather_opinion_2018.csv\"\n","\n","\n","df_main = pd.read_csv(link_main)\n","df_opinion = pd.read_csv(link_opinion)\n","print(df_main.head())\n","print(df_opinion.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["start_year, end_year = 2017, 2020\n","\n","\n","def create_df_wild_with2date(start_year, end_year):\n","    import pandas as pd\n","    # Initiate an empty DataFrame\n","    dftotal = pd.DataFrame()\n","    df_year = pd.DataFrame()\n","    # Collect both DataFrames each year\n","    plage_year = [year for year in range(start_year, end_year)]\n","\n","    for var_year in plage_year:\n","        year = str(var_year)\n","        if end_year < 2019:\n","                # print(var_year)\n","                year = str(var_year)\n","                link_main = \"https://raw.githubusercontent.com/WildCodeSchool/data-training-resources/main/quests/weather_main_\" + year + \".csv\"\n","                link_opinion = \"https://raw.githubusercontent.com/WildCodeSchool/data-training-resources/main/quests/weather_opinion_\" + year + \".csv\"\n","                df_main = pd.read_csv(link_main)\n","                df_opinion = pd.read_csv(link_opinion)\n","                # Apply your merge, cleaning and fillna function on the current year\n","                df_year = mergeDF(df_main, df_opinion)\n","                dftotal = pd.concat([dftotal, df_year])\n","        if start_year >= 2019:\n","            # for var_year in plage_year:\n","                # year = str(var_year)\n","                # Chaque année depuis 2019 (inclus) a une seule source avec ce format de nom de fichier : weatherYYYY.csv\n","                df_year_up2019 = \"https://raw.githubusercontent.com/WildCodeSchool/data-training-resources/main/quests/weather\" + year + \".csv\"\n","                df_year_up2019 = df_year.rename(\n","                    columns={'date': 'DATE'}, inplace=True)\n","                # Concat with the global DF\n","                dftotal = pd.concat([dftotal, df_year])\n","    return dftotal\n","\n","\n","def mergeDF(df_main, df_opinion):\n","    df_opinion.rename(columns={'date': 'DATE'}, inplace=True)\n","    dfnew = pd.merge(left=df_main,\n","                     right=df_opinion,\n","                     left_on='DATE',\n","                     right_on=\"DATE\",\n","                     how='left')\n","    # on va renommer la colonne date avec le meme format que la table main\n","    # liste_colonnes_opinion = df_opinion.columns.to_list()\n","    # print(liste_colonnes_opinion)\n","    return dfnew\n","\n","\n","def translate(opinion):\n","    try:\n","        # nettoyage et typage de la variable\n","        opinion = str(opinion).strip().lower()\n","        # print(opinion)\n","        translations = {\n","            \"very bad\": \"très mauvais\",\n","            \"bad\": \"mauvais\",\n","            \"not good not bad\": \"ni bon ni mauvais\",\n","            \"good\": \"bon\",\n","            \"very good\": \"très bon\"\n","        }\n","        return translations[opinion]\n","    except KeyError:\n","        return opinion"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dftotal = create_df_wild_with2date(2017, 2018)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# mergeDF(df_main, df_opinion)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dftotal = create_df_wild_with2date(2017, 2020)"]},{"cell_type":"markdown","metadata":{},"source":["### INFOS SUR LE DATASET"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# INFOS SUR LE DATASET\n","\"\"\"fonction resumant les informations essentielles à connaittre sur un dataset\n","\"\"\"\n","\n","\n","def info_dataframe(dataframe):\n","    df = dataframe\n","    print(\"\\ntaille: \", df.size, \"valeurs.\", \" \\nDimensions:\", df.shape)\n","    print(\"\\nNombre de na:\", df.isna().all().size,\n","          \"\\nNombre de null:\", df.isnull().all().size)\n","    print(\"\\nliste nom des colonnes: \\n\", df.columns)\n","    print(\"\\nliste colonnes comportant des NA: \\n\", df[df.isna()].columns)\n","    try:\n","        print(\"\\nliste nom des valeurs uniques par ligne: \\n\",\n","              df[df.iloc[:, 1:]].value.unique())\n","        for col in df.columns[1:]:\n","            if df[col].dtype == 'object' and df[col].dtype != 'int*' and df[col].dtype != 'float*':\n","                print(f\"\\nValeurs uniques pour {col} : \\n\", df[col].unique())\n","    except:\n","        print(\"\\nil y a trop de colonnes pour sortir les valeurs uniques de chacunes\\n\")\n","        # pass\n","    try:\n","        print(\"\\nInfo\")\n","        print(df.info())\n","        print(\"\\nDescribe\")\n","        print(df.describe())\n","        print(\"\\nHead\")\n","        print(df.head(5))\n","    except:\n","        print(\"dataFrame inexploitable, veuillez le verifier\")\n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# test fonction info\n","info_dataframe(dftotal)"]},{"cell_type":"markdown","metadata":{},"source":["## MAKE A FUNCTION TO CREATE DATAFRAMES"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# test\n","try:\n","    print(dftotal[\"DATE\"])\n","except:\n","    print(dftotal.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"njsItedL3utQ"},"outputs":[],"source":["# def merge_and_fill(DataFrameMain, DataFrameOpinion):\n","def add_col_and_fill(dftotal):\n","    import numpy as np\n","    # Initialisation du dataframe de sortie\n","    df = pd.DataFrame\n","    df = dftotal\n","    #\n","    # MERGE déja intégré dans la fonction create_df_wild_with2date()\n","\n","    #  formatage colonne date en date, si déja fait on ne fait pas\n","    try:\n","        df['DATE'] = pd.to_datetime(df['DATE'])\n","        df.set_index('DATE', inplace=True)\n","    except:\n","        pass\n","\n","    # FILL IN MISSING VALUES\n","    # remplacement de na par 0\n","    liste_colonnes_nulle = [\"TOTAL_SNOW_MM\", ]\n","    for column_name in liste_colonnes_nulle:\n","        df[column_name] = df[column_name].fillna(0, inplace=True)\n","\n","    # remplacement de na par la valeur mediane\n","    liste_colonnes_mediane = [\"WEATHER_CODE_EVENING\"]\n","    for column_name in liste_colonnes_mediane:\n","        median_value = df[column_name].median()\n","        df[column_name] = df[column_name].fillna(median_value, inplace=True)\n","    # \"UV_INDEX\"\n","    # remplacement de na par bfill et ffill\n","    liste_colonnes_mediane = [\"UV_INDEX\"]\n","    for column_name in liste_colonnes_mediane:\n","        df[column_name] = df[column_name].fillna(method='ffill', inplace=True)\n","        df[column_name] = df[column_name].fillna(method='bfill', inplace=True)\n","        # Remplir les valeurs manquantes restantes avec 0\n","        df[column_name] = df[column_name].fillna(0, inplace=True)\n","\n","    # ADD NEW COLUMNS\n","    try:\n","        # ajout colonne DAY\n","        df['DAY'] = df.index.day\n","        # ajout colonne Month\n","        df['MONTH'] = df.index.month\n","\n","        # colonne flag\n","        df['flag'] = df['OPINION'].isna()\n","        df['flag'].value_counts()\n","    except:\n","        pass\n","\n","    # \"OPINION\"\n","    # remplacement de na par unknown\n","    liste_colonnes_mediane = [\"OPINION\"]\n","    for column_name in liste_colonnes_mediane:\n","        df[column_name] = df[column_name].fillna(\"unknown\", inplace=True)\n","\n","    # remplacement des valeurs manquantes des colonnes int ou float par 0\n","    # sinon remplacement des valeurs manquantes des colonnes objet par unkwon\n","    for column in df.columns[df.isnull().any()]:\n","        if np.issubdtype(df[column].dtype, np.number):\n","            df[column].fillna(0, inplace=True)\n","        # else:\n","        #     df[column].fillna(\"unknown\", inplace=True)\n","\n","    #  Verification qu'il ne reste plus de valeurs na\n","    for column in df.columns:\n","        print(\"I have \", df.isna().all().size,\n","              \"missing values in the column\", column)\n","\n","    # TRANSLATE OPINION\n","    df['OPINION'] = df['OPINION'].apply(translate)\n","\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# test de la fonction\n","add_col_and_fill(dftotal)"]},{"cell_type":"markdown","metadata":{"id":"851Xnj1M4_xd"},"source":["## Execution with a loop\n","You will execute your function in a 9 rounds loop, once per year, and agregate this in a new big DataFrame with 24 columns and lots of rows."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AE09BUYX5blp"},"outputs":[],"source":["# Each year between 2010 and 2018 (included) has 2 sources : weather_main_YYYY.csv and weather_opinion_YYYY.csv\n","\n","# for year in range(2010, 2019):\n","dftotal = create_df_wild_with2date(2010, 2019)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dftotal.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["add_col_and_fill(dftotal)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# test fonction info\n","info_dataframe(dftotal)"]},{"cell_type":"markdown","metadata":{"id":"c5YtwMyw6BiW"},"source":["## Add 2019 to 2022"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pTiJ3fAa6FEC"},"outputs":[],"source":["# Each year since 2019 (included) has 1 source : weatherYYYY.csv\n","# Chaque année depuis 2019 (inclus) a une seule source avec ce format de nom de fichier : weatherYYYY.csv\n","link2019 = \"https://raw.githubusercontent.com/WildCodeSchool/data-training-resources/main/quests/weather2019.csv\""]},{"cell_type":"markdown","metadata":{"id":"a2DO5esW6Weh"},"source":["# Draw a scatterplot\n","With Date on X-Axis and Max Temperature on Y-axis\n","\n","The result must have 13 seasonality for the 13 summers/winters alternance.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j7TKmTuSe1JP"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"MnFjmbITe0mS"},"source":["\n","Find appropriate dataviz to answer to this question :\n","\n","Which year had the best weather? Are years very different or not ?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fDneGuBle8cs"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## SOURCES"]},{"cell_type":"markdown","metadata":{},"source":["### Application des mêmes filtres et merge que pour la base df2018"]}],"metadata":{"colab":{"provenance":[{"file_id":"1xAOk19Y0JRq0UTdoYGEV40-pgRWQbC2f","timestamp":1701678466078}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
