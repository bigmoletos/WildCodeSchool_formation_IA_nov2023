{"cells":[{"cell_type":"markdown","metadata":{"id":"BkuwUPOKcaKJ"},"source":["# Apprentissage par renforcement"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"SEq8dgK3B9D2"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import time\n","\n","# N_ETATS : Le nombre d'états possibles avant d'atteindre la cible.\n","# ACTIONS : Les actions possibles de l'agent ('gauche' ou 'droite').\n","# EPSILON : La probabilité de choisir une action au hasard plutôt que la meilleure action connue, pour explorer l'environnement.\n","# ALPHA : Le taux d'apprentissage, qui détermine à quel point les nouvelles informations remplacent les anciennes.\n","# GAMMA : Le facteur de remise, qui détermine l'importance des récompenses futures.\n","# MAX_CYCLES : Le nombre maximum de cycles d'entraînement.\n","# TPS_MOUV : Le temps entre les mouvements, pour la simulation.\n","\n","# A---CIBLE\n","# Le nombre de positions possibles avant d'atteindre la cible avec le moins de déplacements possible\n","N_ETATS = 5\n","# Les actions réalisables par l'agent\n","ACTIONS = ['gauche', 'droite']\n","# La valeur qui permet d'indiquer si une action de l'agent est aléatoire ou encore basée sur la qualité\n","EPSILON = 0.9\n","# Le taux d'apprentissage qui varie de 0 (l'agent n'a rien appris) à 1 (l'agent ne tient compte que de la dernière\n","#information apprise)\n","ALPHA = 0.1\n","# Le coefficient de réduction\n","GAMMA = 0.7\n","# Le nombre de cycles\n","MAX_CYCLES = 5\n","# La vitesse des mouvements\n","TPS_MOUV = 0.1\n","\n","# Construction d'une Q table\n","def Construire_q_table(n_etats, actions):\n","    \"\"\"\n","    Construit une Q-table initialisée à zéro pour un nombre donné d'états et d'actions.\n","\n","    :param n_etats: Nombre d'états dans l'environnement.\n","    :param actions: Liste des actions possibles.\n","    :return: DataFrame pandas représentant la Q-table.\n","    \"\"\"\n","    table = pd.DataFrame(np.zeros((n_etats, len(actions))),columns=actions)\n","    print(f\"\\nQ table :\\n{table} \\n\")\n","    return table\n","\n","# Choix de l'action en fonction de l'état et de la Q table\n","def choix_action(etat, q_table):\n","    \"\"\"\n","    Sélectionne une action pour un état donné en utilisant la politique epsilon-greedy.\n","\n","    :param etat: L'état actuel de l'agent.\n","    :param q_table: La Q-table utilisée pour choisir l'action.\n","    :return: L'action choisie.\n","    \"\"\"\n","    etat_actions = q_table.iloc[etat, :]\n","    print(f\"\\netat_actions :\\n{etat_actions} \\n\")\n","    if (np.random.uniform() > EPSILON) or ((etat_actions ==0).all()):\n","        nom_action = np.random.choice(ACTIONS)\n","    else:\n","        nom_action = etat_actions.idxmax()\n","    print(f\"\\nnom_action :\\n{nom_action} \\n\")\n","    return nom_action\n","\n","# Fonction qui indique le nouvel état et la récompense en\n","#fonction de l'état et de l'action\n","def nouv_etat_r(E, A):\n","    \"\"\"\n","    Détermine le nouvel état et la récompense basés sur l'état actuel et l'action prise.\n","\n","    :param E: L'état actuel.\n","    :param A: L'action effectuée.\n","    :return: Le nouvel état et la récompense associée.\n","    \"\"\"\n","    if A == 'droite':\n","        if E == N_ETATS - 2:\n","            E_ = 'cible'\n","            R = 1\n","        else:\n","            E_ = E + 1\n","            R = 0\n","    else:\n","        R = 0\n","        if E == 0:\n","            E_ = E\n","        else:\n","            E_ = E - 1\n","    print(f\"\\nE_ :\\n{E_} ,R  {R} \\n\")\n","    return E_, R\n","\n","# Fonction qui met à jour l'environnement\n","def maj_env(S, cycle, c_etape):\n","    \"\"\"\n","    Met à jour l'environnement de simulation en affichant l'état actuel et le cycle.\n","\n","    :param S: L'état actuel ou 'cible' si atteint.\n","    :param cycle: Le numéro du cycle actuel.\n","    :param c_etape: Le compteur d'étapes dans le cycle actuel.\n","    \"\"\"\n","    env_list = ['-']*(N_ETATS-1) + ['Cible']\n","    # print(f\"\\nenv_list :\\n{env_list} \\n\")\n","    if S == 'cible':\n","        interaction = 'Cycle %s: nombre_pas = %s' % (cycle+1,c_etape)\n","        print('\\r{}'.format(interaction), end='')\n","        time.sleep(1)\n","        print('\\r', end='')\n","    else:\n","        env_list[S] = 'A'\n","        interaction = ''.join(env_list)\n","        print('\\r{}'.format(interaction), end='')\n","        time.sleep(TPS_MOUV)\n","\n","def apprentissage_renforcement():\n","    \"\"\"\n","    Cette fonction implémente l'algorithme d'apprentissage par renforcement.\n","    Elle construit une table Q et effectue un certain nombre de cycles d'apprentissage.\n","    Chaque cycle consiste en une série d'étapes jusqu'à atteindre l'état 'cible'.\n","    À chaque étape, une action est choisie et l'état est mis à jour en fonction de cette action.\n","    La table Q est mise à jour à chaque étape en utilisant l'équation de Bellman.\n","    \"\"\"\n","\n","    # Construire la table Q initiale\n","    q_table = Construire_q_table(N_ETATS, ACTIONS)\n","    print(f\"\\nq_table :\\n{q_table} \\n\")\n","    # Boucle sur le nombre maximal de cycles\n","    for cycle in range(MAX_CYCLES):\n","        c_etape = 0  # Initialiser le compteur d'étapes\n","        E = 0  # Initialiser l'état\n","        fin_cycle = False  # Indicateur de fin de cycle\n","\n","        # Mettre à jour l'environnement\n","        maj_env(E, cycle, c_etape)\n","\n","        # Boucle jusqu'à la fin du cycle\n","        while not fin_cycle:\n","            # Choisir une action en fonction de l'état et de la table Q\n","            A = choix_action(E, q_table)\n","            # Obtenir le nouvel état et la récompense en fonction de l'état actuel et de l'action choisie\n","            E_, R = nouv_etat_r(E, A)\n","            # Prédire la valeur Q pour l'état actuel et l'action choisie\n","            q_pred = q_table.loc[E, A]\n","            # Si le nouvel état n'est pas l'état 'cible'\n","            if E_ != 'cible':\n","                # Calculer la valeur cible Q en utilisant l'équation de Bellman\n","                q_cible = R + GAMMA * q_table.iloc[E_, :].max()\n","            else:\n","                # Si le nouvel état est l'état 'cible', la valeur cible Q est simplement la récompense\n","                q_cible = R\n","                # Indiquer la fin du cycle\n","                fin_cycle = True\n","            # Mettre à jour la valeur Q pour l'état actuel et l'action choisie\n","            q_table.loc[E, A] += ALPHA * (q_cible - q_pred)\n","            # Mettre à jour l'état\n","            E = E_\n","            # Mettre à jour l'environnement\n","            maj_env(E, cycle, c_etape+1)\n","            # Incrémenter le compteur d'étapes\n","            c_etape += 1\n","\n","    # Retourner la table Q après l'apprentissage\n","    return q_table\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11045,"status":"ok","timestamp":1670937053857,"user":{"displayName":"Patrick Wampé","userId":"02453528432425325630"},"user_tz":-60},"id":"ZUFgJPjJB9F-","outputId":"ea91094f-ec19-44dd-cf0f-8d9c267e1f27"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Q table :\n","   gauche  droite\n","0     0.0     0.0\n","1     0.0     0.0\n","2     0.0     0.0\n","3     0.0     0.0\n","4     0.0     0.0 \n","\n","\n","q_table :\n","   gauche  droite\n","0     0.0     0.0\n","1     0.0     0.0\n","2     0.0     0.0\n","3     0.0     0.0\n","4     0.0     0.0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","1 ,R  0 \n","\n","-A--Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 1, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","2 ,R  0 \n","\n","--A-Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 2, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","1 ,R  0 \n","\n","-A--Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 1, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","1 ,R  0 \n","\n","-A--Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 1, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","2 ,R  0 \n","\n","--A-Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 2, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","3 ,R  0 \n","\n","---ACible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 3, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","2 ,R  0 \n","\n","--A-Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 2, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","1 ,R  0 \n","\n","-A--Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 1, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","1 ,R  0 \n","\n","-A--Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 1, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","1 ,R  0 \n","\n","-A--Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 1, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","1 ,R  0 \n","\n","-A--Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 1, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","2 ,R  0 \n","\n","--A-Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 2, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","1 ,R  0 \n","\n","-A--Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 1, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","2 ,R  0 \n","\n","--A-Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 2, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","3 ,R  0 \n","\n","---ACible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 3, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","2 ,R  0 \n","\n","--A-Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 2, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","3 ,R  0 \n","\n","---ACible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 3, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","2 ,R  0 \n","\n","--A-Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 2, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","3 ,R  0 \n","\n","---ACible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 3, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","cible ,R  1 \n","\n","A---Ciblenombre_pas = 34\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","1 ,R  0 \n","\n","-A--Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 1, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","2 ,R  0 \n","\n","--A-Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 2, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","1 ,R  0 \n","\n","-A--Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 1, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","2 ,R  0 \n","\n","--A-Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 2, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","3 ,R  0 \n","\n","---ACible\n","etat_actions :\n","gauche    0.0\n","droite    0.1\n","Name: 3, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","cible ,R  1 \n","\n","A---Ciblenombre_pas = 8\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","1 ,R  0 \n","\n","-A--Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 1, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","2 ,R  0 \n","\n","--A-Cible\n","etat_actions :\n","gauche    0.000\n","droite    0.007\n","Name: 2, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","3 ,R  0 \n","\n","---ACible\n","etat_actions :\n","gauche    0.00\n","droite    0.19\n","Name: 3, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","2 ,R  0 \n","\n","--A-Cible\n","etat_actions :\n","gauche    0.0000\n","droite    0.0196\n","Name: 2, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","3 ,R  0 \n","\n","---ACible\n","etat_actions :\n","gauche    0.001372\n","droite    0.190000\n","Name: 3, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","cible ,R  1 \n","\n","A---Ciblenombre_pas = 9\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","gauche \n","\n","\n","E_ :\n","0 ,R  0 \n","\n","A---Cible\n","etat_actions :\n","gauche    0.0\n","droite    0.0\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","1 ,R  0 \n","\n","-A--Cible\n","etat_actions :\n","gauche    0.00000\n","droite    0.00049\n","Name: 1, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","2 ,R  0 \n","\n","--A-Cible\n","etat_actions :\n","gauche    0.00000\n","droite    0.03094\n","Name: 2, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","3 ,R  0 \n","\n","---ACible\n","etat_actions :\n","gauche    0.001372\n","droite    0.271000\n","Name: 3, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","cible ,R  1 \n","\n","A---Ciblenombre_pas = 6\n","etat_actions :\n","gauche    0.000000\n","droite    0.000034\n","Name: 0, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","1 ,R  0 \n","\n","-A--Cible\n","etat_actions :\n","gauche    0.000000\n","droite    0.002607\n","Name: 1, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","2 ,R  0 \n","\n","--A-Cible\n","etat_actions :\n","gauche    0.000000\n","droite    0.046816\n","Name: 2, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","3 ,R  0 \n","\n","---ACible\n","etat_actions :\n","gauche    0.001372\n","droite    0.343900\n","Name: 3, dtype: float64 \n","\n","\n","nom_action :\n","droite \n","\n","\n","E_ :\n","cible ,R  1 \n","\n"," Q-table :ombre_pas = 4\n","      gauche    droite\n","0  0.000000  0.000213\n","1  0.000000  0.005623\n","2  0.000000  0.066207\n","3  0.001372  0.409510\n","4  0.000000  0.000000\n"]}],"source":["# Lancement de l'algorithme\n","q_table = apprentissage_renforcement()\n","print('\\r Q-table :\\n', q_table)\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" Q-table :ombre_pas = 43\n","    gauche    droite\n","0     0.0  0.000158\n","1     0.0  0.004194\n","2     0.0  0.057022\n","3     0.0  0.409510\n","4     0.0  0.000000\n"," Q-table :ombre_pas = 40\n","      gauche    droite\n","0  0.000000  0.000213\n","1  0.000000  0.004552\n","2  0.000034  0.057022\n","3  0.000000  0.409510\n","4  0.000000  0.000000\n"," Q-table :ombre_pas = 41\n","      gauche    droite\n","0  0.000000  0.000266\n","1  0.000005  0.005623\n","2  0.000034  0.070800\n","3  0.002563  0.409510\n","4  0.000000  0.000000\n"," Q-table :ombre_pas = 43\n","    gauche    droite\n","0     0.0  0.000158\n","1     0.0  0.004194\n","2     0.0  0.057022\n","3     0.0  0.409510\n","4     0.0  0.000000\n"," Q-table :ombre_pas = 42\n","    gauche    droite\n","0     0.0  0.000158\n","1     0.0  0.004194\n","2     0.0  0.057022\n","3     0.0  0.409510\n","4     0.0  0.000000\n"," Q-table :ombre_pas = 40\n","    gauche    droite\n","0     0.0  0.000158\n","1     0.0  0.004194\n","2     0.0  0.057022\n","3     0.0  0.409510\n","4     0.0  0.000000\n"," Q-table :ombre_pas = 46\n","    gauche    droite\n","0     0.0  0.000158\n","1     0.0  0.004194\n","2     0.0  0.057022\n","3     0.0  0.409510\n","4     0.0  0.000000\n"," Q-table :ombre_pas = 47\n","    gauche    droite\n","0     0.0  0.000158\n","1     0.0  0.004194\n","2     0.0  0.057022\n","3     0.0  0.409510\n","4     0.0  0.000000\n"," Q-table :ombre_pas = 44\n","    gauche    droite\n","0     0.0  0.000158\n","1     0.0  0.004194\n","2     0.0  0.057022\n","3     0.0  0.409510\n","4     0.0  0.000000\n"," Q-table :ombre_pas = 48\n","    gauche    droite\n","0     0.0  0.000158\n","1     0.0  0.004194\n","2     0.0  0.057022\n","3     0.0  0.409510\n","4     0.0  0.000000\n"]}],"source":["for _ in range(10):\n","    q_table = apprentissage_renforcement()\n","    print('\\r Q-table :\\n', q_table)\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1Iq8CNSGB1B9qFhNaKjBqw4KRCuLKlrdb","timestamp":1707915689669}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
