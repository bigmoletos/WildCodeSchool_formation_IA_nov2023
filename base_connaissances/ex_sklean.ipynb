{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Charger les données du Titanic\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "titanic['survived'] = titanic['survived'].apply(\n",
    "    lambda x: 'did not survive' if x == 0 else 'survived')\n",
    "\n",
    "# Extraire les caractéristiques et les résultats\n",
    "X = titanic.drop('survived', axis=1)\n",
    "y = titanic['survived']\n",
    "\n",
    "# Convertir les variables catégorielles en variables binaires\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shape: (891, 30) \n",
      "list columns :\n",
      "['pclass', 'age', 'sibsp', 'parch', 'fare', 'adult_male', 'alone', 'sex_female', 'sex_male', 'embarked_C', 'embarked_Q', 'embarked_S', 'class_First', 'class_Second', 'class_Third', 'who_child', 'who_man', 'who_woman', 'deck_A', 'deck_B', 'deck_C', 'deck_D', 'deck_E', 'deck_F', 'deck_G', 'embark_town_Cherbourg', 'embark_town_Queenstown', 'embark_town_Southampton', 'alive_no', 'alive_yes'] \n",
      "liste des colonnes numeriques: \n",
      "['pclass', 'age', 'sibsp', 'parch', 'fare']\n",
      "\n",
      "liste des colonnes non numeriques: \n",
      "['adult_male', 'alone', 'sex_female', 'sex_male', 'embarked_C', 'embarked_Q', 'embarked_S', 'class_First', 'class_Second', 'class_Third', 'who_child', 'who_man', 'who_woman', 'deck_A', 'deck_B', 'deck_C', 'deck_D', 'deck_E', 'deck_F', 'deck_G', 'embark_town_Cherbourg', 'embark_town_Queenstown', 'embark_town_Southampton', 'alive_no', 'alive_yes'] \n",
      "Colonne avec des na :pclass                       0\n",
      "age                        177\n",
      "sibsp                        0\n",
      "parch                        0\n",
      "fare                         0\n",
      "adult_male                   0\n",
      "alone                        0\n",
      "sex_female                   0\n",
      "sex_male                     0\n",
      "embarked_C                   0\n",
      "embarked_Q                   0\n",
      "embarked_S                   0\n",
      "class_First                  0\n",
      "class_Second                 0\n",
      "class_Third                  0\n",
      "who_child                    0\n",
      "who_man                      0\n",
      "who_woman                    0\n",
      "deck_A                       0\n",
      "deck_B                       0\n",
      "deck_C                       0\n",
      "deck_D                       0\n",
      "deck_E                       0\n",
      "deck_F                       0\n",
      "deck_G                       0\n",
      "embark_town_Cherbourg        0\n",
      "embark_town_Queenstown       0\n",
      "embark_town_Southampton      0\n",
      "alive_no                     0\n",
      "alive_yes                    0\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "df head :\n",
      "   pclass   age  sibsp  parch     fare  adult_male  alone  sex_female  \\\n",
      "0       3  22.0      1      0   7.2500        True  False       False   \n",
      "1       1  38.0      1      0  71.2833       False  False        True   \n",
      "\n",
      "   sex_male  embarked_C  ...  deck_C  deck_D  deck_E  deck_F  deck_G  \\\n",
      "0      True       False  ...   False   False   False   False   False   \n",
      "1     False        True  ...    True   False   False   False   False   \n",
      "\n",
      "   embark_town_Cherbourg  embark_town_Queenstown  embark_town_Southampton  \\\n",
      "0                  False                   False                     True   \n",
      "1                   True                   False                    False   \n",
      "\n",
      "   alive_no  alive_yes  \n",
      "0      True      False  \n",
      "1     False       True  \n",
      "\n",
      "[2 rows x 30 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Résumé des informations du dataframe\n",
    "your_dataframe = X\n",
    "print(f\"\\nshape: {your_dataframe.shape} \\nlist columns :\\n{\n",
    "      your_dataframe.columns.tolist()} \")\n",
    "print(f\"liste des colonnes numeriques: \\n{\n",
    "      your_dataframe.select_dtypes(include=[np.number]).columns.tolist()}\\n\")\n",
    "print(f\"liste des colonnes non numeriques: \\n{\n",
    "      your_dataframe.select_dtypes(exclude=[np.number]).columns.tolist()} \")\n",
    "print(f\"Colonne avec des na :{your_dataframe.isna().sum()} \\n\")\n",
    "print(f\"\\ndf head :\\n{your_dataframe.head(2)} \\n\")\n",
    "# print(f\"\\ndf describe :\\n{your_dataframe.describe()} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un objet de normalisation\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normaliser les données\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Résumé des informations du dataframe\u001b[39;00m\n\u001b[0;32m      2\u001b[0m your_dataframe\u001b[38;5;241m=\u001b[39mX\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mshape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myour_dataframe\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mlist columns :\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43myour_dataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliste des colonnes numeriques: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00myour_dataframe\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mnumber])\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliste des colonnes non numeriques: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00myour_dataframe\u001b[38;5;241m.\u001b[39mselect_dtypes(exclude\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mnumber])\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# Résumé des informations du dataframe\n",
    "your_dataframe=X\n",
    "print(f\"\\nshape: {your_dataframe.shape} \\nlist columns :\\n{your_dataframe.columns.tolist()} \")\n",
    "print(f\"liste des colonnes numeriques: \\n{your_dataframe.select_dtypes(include=[np.number]).columns.tolist()}\\n\")\n",
    "print(f\"liste des colonnes non numeriques: \\n{your_dataframe.select_dtypes(exclude=[np.number]).columns.tolist()} \")\n",
    "print(f\"Colonne avec des na :{your_dataframe.isna().sum()} \\n\")\n",
    "print(f\"\\ndf head :\\n{your_dataframe.head(2)} \\n\")\n",
    "print(f\"\\ndf describe :\\n{your_dataframe.describe()} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Créer un objet de pipeline\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                ('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "# Définir les paramètres du modèle\n",
    "params = {'classifier__max_depth': 5, 'classifier__min_samples_split': 10}\n",
    "\n",
    "# Définir les paramètres du pipeline\n",
    "pipe.set_params(**params)\n",
    "\n",
    "# Remplir le pipeline avec des données d'entraînement et entraîner le modèle\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Créer un objet de l'arbre de décision\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# Ajuster l'arbre de décision aux données d'entraînement\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# Visualiser l'arbre de décision\n",
    "tree.plot_tree(dtree)\n",
    "\n",
    "# Créer une matrice de corrélation\n",
    "corr = titanic.corr()\n",
    "\n",
    "# Créer un heatmap\n",
    "sns.heatmap(corr, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOP  des CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_fold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m tscv \u001b[38;5;241m=\u001b[39m TimeSeriesSplit(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# define the predefined split cross-validation method\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m ps \u001b[38;5;241m=\u001b[39m PredefinedSplit(\u001b[43mtest_fold\u001b[49m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# define the repeated k-fold cross-validation method\u001b[39;00m\n\u001b[0;32m     31\u001b[0m rkf \u001b[38;5;241m=\u001b[39m RepeatedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_repeats\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_fold' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold, LeaveOneOut, StratifiedKFold, GroupKFold, ShuffleSplit, TimeSeriesSplit, PredefinedSplit, RepeatedKFold, RepeatedStratifiedKFold, LeavePOut\n",
    "\n",
    "# define the dataset\n",
    "X, y = make_classification(n_samples=100, n_features=2,\n",
    "                           n_informative=2, n_redundant=0, random_state=42)\n",
    "\n",
    "# define the k-fold cross-validation method\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# define the leave-one-out cross-validation method\n",
    "loocv = LeaveOneOut()\n",
    "\n",
    "# define the stratified k-fold cross-validation method\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# define the group k-fold cross-validation method\n",
    "gkf = GroupKFold(n_splits=10)\n",
    "\n",
    "# define the shuffle split cross-validation method\n",
    "ss = ShuffleSplit(n_splits=10, test_size=0.33, random_state=42)\n",
    "\n",
    "# define the time series split cross-validation method\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# define the predefined split cross-validation method\n",
    "ps = PredefinedSplit(test_fold)\n",
    "\n",
    "# define the repeated k-fold cross-validation method\n",
    "rkf = RepeatedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "\n",
    "# define the repeated stratified k-fold cross-validation method\n",
    "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "\n",
    "# define the leave-p-out cross-validation method\n",
    "lpocv = LeavePOut(p=2)\n",
    "\n",
    "# create a figure with 5 rows and 2 columns\n",
    "fig, axs = plt.subplots(nrows=5, ncols=2, figsize=(10, 20))\n",
    "\n",
    "# plot the scatter plot for each method of cross-validation\n",
    "for ax, cv_method in zip(axs.flatten(), [kfold, loocv, skf, gkf, ss, tscv, ps, rkf, rskf, lpocv]):\n",
    "    for train_ix, test_ix in cv_method.split(X, y):\n",
    "        # select rows for train and test\n",
    "        train_X, test_X = X[train_ix], X[test_ix]\n",
    "        train_y, test_y = y[train_ix], y[test_ix]\n",
    "        # scatter plot of train and test dataset\n",
    "        ax.scatter(train_X[:, 0], train_X[:, 1], label='Train')\n",
    "        ax.scatter(test_X[:, 0], test_X[:, 1], label='Test')\n",
    "    ax.set_title(str(cv_method).split('(')[0])\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
